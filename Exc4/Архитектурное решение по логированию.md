# Задание 4. Логирование

## Какие логи нужно собирать в приложении

Необходимо собирать логи из систем Shop API, MES API, CRM API, а впоследствии также из серверов, выдающих статику для Internet Shop и MES, CRM.

Общие данные для всех логов включают:
- дату и время;
- идентификатор трассировки (для прослеживания и логгирования), который передается через OpenTelemetry.

О движении заказа по статусам:
Для этого логи должны содержать:
- идентификатор заказа;
- идентификатор покупателя;
- источник заказа (онлайн-магазин или B2C);
- данные об операторе, выполняющем заказ;
- систему/компонент, выполняющий логгирование (для последующей централизованной обработки в ELK).

Логгирование процесса загрузки файлов моделей:
- Включает данные о заказе;
- Размер модели;
- Источник модели (конструктор или произвольная загрузка).

Логгирование процесса расчёта:
- Включает данные о заказе;
- Информацию об исходной модели: размер, источник (конструктор или произвольная модель);
- Начало расчёта;
- Окончание расчёта.

**ERROR/FATAL**: Каждый из сервисов должен также предоставлять эти данные в случае ошибок с уровнем INFO в случае нормального выполнения операций.

## Мотивация

Основная причина внедрения логирования — повышение уровня наблюдаемости и сопровождения системы за счёт более быстрого и подробного анализа инцидентов, а также оперативного реагирования на них посредством алертов.

Метрики здесь аналогичны трейсингу:
- Среднее время восстановления после сбоя (MTTR — Mean Time to Recovery);
- Затраты на обслуживание (Maintenance Costs);
- Коэффициент доступности (Uptime).

В первую очередь имеет смысл покрыть логированием MES API, так как этот компонент выглядит наиболее проблемным. Далее следует заняться CRM API и SHOP API для более полного отслеживания потенциальных проблем при перемещении заказа по статусам.

## Предлагаемое решение

![](jewerly_c4_model_with_logs.drawio.png "Добавление логирования")

### Технологии

Предлагается использовать Filebeat, который будет отправлять данные в Logstash. После преобразования логи будут отправлены в OpenSearch для индексирования и станут источником данных для панели мониторинга OpenSearch Dashboard.

### Безопасность

Предполагается авторизация пользователей через протокол OpenID Connect.

### Политика хранения индекса

**Горячая фаза**: Индексы находятся в активной фазе, когда активно поступают новые данные. При достижении максимального размера (25 ГБ) или количества документов (5 млн) создаётся новый индекс.

**Тёплая фаза**: Через две недели индексы переходят в тёплую фазу, где выполняется оптимизация данных (сжатие сегментов и уменьшение числа шардов).

**Холодная фаза**: Ещё через четыре недели индексы становятся доступны только для чтения.

**Фаза удаления**: По истечении 60 дней старые индексы удаляются.

## Мероприятия для превращения системы сбора логов в систему анализа логов

Необходимо настроить алертинг для отслеживания зависших заказов, поскольку это является актуальной проблемой бизнеса. Также стоит предусмотреть алерты при превышении нормальных показателей ошибок.

Кроме того, важно отслеживать резкое увеличение разницы между входящими запросами на создание заказов и загрузкой файлов моделей украшений, так как это может перегрузить систему и заполнить очередь.

## Критерии для выбора технологий
| Критерий               | ELK Stack (Elasticsearch, Logstash, Kibana) | OpenSearch | Splunk | Graylog | Fluentd | Loki |
|------------------------|---------------------------------------------|------------|--------|---------|---------|------|
| **Лицензия**          | Elastic License (смешанная: бесплатное ядро, но ограничения на коммерческое использование) | Apache 2.0 (полностью открытый, без ограничений) | Проприетарная (коммерческое ПО, требует подписки) | GPL v3 (Community Edition), Enterprise лицензия | Apache 2.0 (полностью открытый, поддерживается сообществом) | AGPL v3 (требует публикации изменений, если используется как сервис) |
| **Масштабируемость**  | Высокая, требуется настройка кластеров     | Высокая, аналогично ELK | Очень высокая, встроенные механизмы | Средняя, сложнее масштабировать | Высокая, горизонтально масштабируемая | Высокая, оптимизирован для хранения больших объемов логов |
| **Сложность настройки** | Высокая, требуется настройка нескольких компонентов | Высокая, но проще ELK | Средняя, есть удобный UI | Средняя | Средняя, конфигурация через плагины | Низкая, легко интегрируется с Prometheus |
| **Сложность поддержки** | Высокая, требует администрирования кластера | Высокая | Средняя, поддержка от вендора | Средняя | Средняя | Низкая, минимум требований |
| **Требования к ресурсам** | Высокие, зависит от объема данных | Высокие | Очень высокие | Средние | Низкие, минимальные требования | Низкие, оптимизирован для хранения в S3 |
| **Гибкость интеграции** | Высокая, много плагинов | Высокая | Высокая, API и интеграции | Средняя | Очень высокая, поддержка многих источников | Средняя, больше для метрик и логов Kubernetes |
| **Документированность** | Отличная, подробные гайды и примеры | Хорошая, но уступает ELK | Отличная, официальные обучающие материалы | Средняя, документация есть, но менее подробная | Хорошая, но часто приходится искать примеры в сообществе | Средняя, документация базовая, но понятная |
| **Поддержка сообществом** | Очень активное, много обсуждений и плагинов | Активное, но уступает ELK | Ограничено, в основном коммерческая поддержка | Среднее, сообщество есть, но не такое большое | Очень активное, особенно в Kubernetes-среде | Развивается, но пока уступает ELK и Fluentd |

---